{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cKiExrJZxir",
        "outputId": "3e125b07-3a43-43e3-e17a-839d3bced47f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('BTC_Trial_NB.csv')\n",
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "rai2u4d5Z2d_",
        "outputId": "60071d52-a640-4b86-d7f9-309d3fc94c34"
      },
      "outputs": [],
      "source": [
        "df1.index = pd.to_datetime(df1['Date'], format='%d/%m/%Y')\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cLGMm6jJZ46X"
      },
      "outputs": [],
      "source": [
        "df = df1.drop(['Date', 'Network Difficulty'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iykNQv_J1yP",
        "outputId": "a0102f75-eb1a-447f-b562-e9b17f29f9b7"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMwNDMVw6zvB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# columns_to_lag_1_7 = ['VOL1','SP500','Interest Rate', 'RUSSELL']\n",
        "columns_to_lag_1_7 = ['VOL1', 'ClosePrice ', 'OpenPrice', 'HighPrice', 'LowPrice','Market Volumn']\n",
        "columns_to_lag_1_5 = [\n",
        "    'Average Block Size', 'Average Transaction Per Block', 'Hash Rate', 'Transactions Per Second','Oil', 'Gold', 'Silver', 'USDEUR', 'USDYUAN',\n",
        "    'Economic Uncertainty', 'Crypto Index']\n",
        "\n",
        "# Create lagged features for 1-7 lags for 'VOL1' and 'ClosePrice'\n",
        "for column in columns_to_lag_1_7:\n",
        "    for lag in range(1, 7):\n",
        "        df[f'{column}_lag{lag}'] = df[column].shift(lag)\n",
        "\n",
        "# Create lagged features for 1-2 lags for the rest of the columns\n",
        "for column in columns_to_lag_1_5:\n",
        "    for lag in range(1, 7):\n",
        "        df[f'{column}_lag{lag}'] = df[column].shift(lag)\n",
        "\n",
        "# Include the original 'VOL1' and 'ClosePrice' columns\n",
        "new_df = df[['VOL1', 'ClosePrice ','Month', 'Year'] + [f'{col}_lag{lag}' for col in columns_to_lag_1_7 for lag in range(1, 7)] + [f'{col}_lag{lag}' for col in columns_to_lag_1_5 for lag in range(1, 7)]]\n",
        "\n",
        "# Drop rows with NaN values created due to lagging\n",
        "new_df = new_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxCtHozb71Ol",
        "outputId": "90de4d80-47cf-429c-d74c-17c1dc25c730"
      },
      "outputs": [],
      "source": [
        "new_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6uZKdVb58w3V"
      },
      "outputs": [],
      "source": [
        "x = new_df.drop(columns = ['ClosePrice ','VOL1'])\n",
        "y = new_df['ClosePrice ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Vg_OnV6b9LoZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "y5bgLWdbaTwD"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled=scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = X_train\n",
        "X_test_scaled=X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYFoBF-bsbrh",
        "outputId": "f52e9f0e-86a8-42b7-9d73-37a2e7e6634c"
      },
      "outputs": [],
      "source": [
        "X_train_scaled.shape, X_test_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "txLyTAh1seMA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "1NIVgREfeol-"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor(\n",
        "    n_estimators=300,        # number of trees in the forest\n",
        "    max_depth= None,            # maximum depth of the tree\n",
        "    min_samples_split=10,     # minimum number of samples required to split an internal node\n",
        "    max_features=0.5,     # number of features to consider when looking for the best split\n",
        "    random_state=24          # random seed for reproducibility\n",
        ")\n",
        "# Fit the model on the training data\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = rf.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LanHNqAXGIwc",
        "outputId": "f89b459a-c08e-452e-d1b1-71ed9a81d056"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RMSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# MAPE\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "#NMSE\n",
        "def nmse(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    variance = np.var(y_true)\n",
        "    return mse / variance\n",
        "\n",
        "#DA\n",
        "def DA(y_true, y_pred):\n",
        "    # Convert the arrays to numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate the direction of change\n",
        "    true_direction = np.sign(np.diff(y_true))\n",
        "    pred_direction = np.sign(np.diff(y_pred))\n",
        "    \n",
        "    # Compare directions\n",
        "    correct_direction = np.sum(true_direction == pred_direction)\n",
        "    total_direction = len(true_direction)\n",
        "    \n",
        "    # Calculate directional accuracy\n",
        "    da = correct_direction / total_direction * 100\n",
        "    \n",
        "    return da"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = y_test\n",
        "y_predi = y_pred\n",
        "\n",
        "print(\"RMSE: \", rmse(y_true, y_predi))\n",
        "print(\"MAPE: \", mape(y_true, y_predi))\n",
        "print(\"NMSE: \", nmse(y_true, y_predi))\n",
        "print(\"DA: \", DA(y_true, y_predi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "0GDp9fuV-xfP",
        "outputId": "5655cb29-ff48-453d-fea3-6fee2bc7b59f"
      },
      "outputs": [],
      "source": [
        "# prediction_df = pd.DataFrame(y_pred, columns=['Predictions'])\n",
        "# prediction_df.index = y_test.index\n",
        "\n",
        "p=700\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.plot(y_test.index[-p:], y_test[-p:], label='Actual Price', color='b')\n",
        "plt.plot(y_test.index[-p:], y_pred[-p:], label='Predicted Price', color='r', alpha=0.7)\n",
        "plt.title('Actual vs Predicted Price (BTC)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = pd.DataFrame(y_pred, columns=['RF'])\n",
        "y_pred.to_csv('RF.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error (RMSE):', metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
        "print('Mean Absolute Percentage Error (MAPE):', metrics.mean_absolute_percentage_error(y_test, y_pred))\n",
        "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
        "print('Max Error:', metrics.max_error(y_test, y_pred))\n",
        "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
        "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))\n",
        "print('Mean Poisson Deviance:', metrics.mean_poisson_deviance(y_test, y_pred))\n",
        "print('Mean Gamma Deviance:', metrics.mean_gamma_deviance(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for feature importances\n",
        "feature_names = x.columns\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features_df = feature_importances_df.head(10)\n",
        "\n",
        "# Plot top 5 feature importances\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.barh(top_features_df['Feature'], top_features_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
