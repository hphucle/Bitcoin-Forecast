{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BTC_Trial_NB.csv')\n",
    "df.index = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "df = df.drop(['Date', 'Month', 'Year', 'Network Difficulty'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_for_training=df[:1848]\n",
    "df_for_testing=df[1848:]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
    "\n",
    "df_for_testing_scaled=scaler.transform(df_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training_scaled.shape, df_for_testing_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
    "            dataY.append(dataset[i,0])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=createXY(df_for_training_scaled,30)\n",
    "testX,testY=createXY(df_for_testing_scaled,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(units, dropout, lr, batch_size, epochs, dense):\n",
    "\n",
    " #LSTM Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(abs(units), input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(LSTM(abs(units)))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(Dense(abs(dense), activation='tanh'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  optimizer = Adam(learning_rate=abs(lr)/10000.0, amsgrad=False)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(trainX, trainY, validation_split=0.2, epochs=abs(epochs), batch_size=abs(batch_size))\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "\n",
    "def evaluate(individual):\n",
    "  units, dropout, lr, batch_size, epochs, dense = individual\n",
    "\n",
    "  units = int(individual[0])\n",
    "  dropout = int(individual[1])\n",
    "  lr = int(individual[2])\n",
    "  batch_size = int(individual[3])\n",
    "  epochs = int(individual[4])\n",
    "  dense = int(individual[5])\n",
    "\n",
    "  print('\\nNum of neurons: ', units, '\\nEpochs:', epochs,'\\nBatch size:',batch_size,\n",
    "        '\\nLearning rate:', abs(lr)/10000.0,'\\nDropout rate:', abs(dropout)/100.0, '\\nDense:', dense)\n",
    "\n",
    "  #LSTM Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(abs(units), input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(LSTM(abs(units)))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(Dense(abs(dense), activation='tanh'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  optimizer = Adam(learning_rate=abs(lr)/10000.0, amsgrad=False)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(trainX, trainY, validation_split=0.2, epochs=abs(epochs), batch_size=abs(batch_size))\n",
    "\n",
    "  # Evaluate the model\n",
    "  loss, accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "  return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(17) \n",
    "\n",
    "# Setup DEAP\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Possible parameter values\n",
    "units = range(16,129)\n",
    "dropout = range(0,41)\n",
    "lr = range(0,101)\n",
    "batch_size = range(32,129)\n",
    "epochs = range(20,101)\n",
    "dense = range(8,65) \n",
    "\n",
    "#Define variables\n",
    "toolbox.register(\"attr_units\", random.choice, units)  # Number of LSTM units\n",
    "toolbox.register(\"attr_dropout\", random.choice, dropout)  # Dropout rate\n",
    "toolbox.register(\"attr_lr\", random.choice, lr)  # Learning rate\n",
    "toolbox.register(\"attr_batch_size\", random.choice, batch_size)  # Batch size\n",
    "toolbox.register(\"attr_epochs\", random.choice, epochs)  # Number of epochs\n",
    "toolbox.register(\"attr_denses\", random.choice, dense)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_units, toolbox.attr_dropout, toolbox.attr_lr,\n",
    "                  toolbox.attr_batch_size, toolbox.attr_epochs, toolbox.attr_denses), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(\"Start time:\", start_time)\n",
    "hof = tools.HallOfFame(1)\n",
    "population = toolbox.population(n=20)\n",
    "algorithms.eaSimple(population, toolbox, cxpb = 0.7, mutpb = 0.2, ngen=20,\n",
    "                    halloffame=hof, verbose=True)\n",
    "best_individual = hof[0]\n",
    "end_time = datetime.now()\n",
    "print('End time:',end_time)\n",
    "time_elapsed = end_time-start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_units = int(best_individual[0])         # Number of LSTM units\n",
    "param_dropout = int(best_individual[1])       # Dropout rate\n",
    "param_lr = int(best_individual[2])            # Learning rate\n",
    "param_batch_size = int(best_individual[3])    # Batch size\n",
    "param_epochs = int(best_individual[4])        # Number of epochs\n",
    "param_denses = int(best_individual[5])        # Number of dense units\n",
    "\n",
    "print(param_units, param_dropout/100,param_lr/10000,param_batch_size, param_epochs, param_denses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(units=param_units,dropout=param_dropout, lr=param_lr,\n",
    "            batch_size=param_batch_size, epochs=param_epochs,dense=param_denses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_best_pred = model.predict(testX).flatten()\n",
    "best_test_result = pd.DataFrame(data= {'Test Pred':y_test_best_pred, 'Actual':testY.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE_tuned = np.sqrt(mean_squared_error(testY, y_test_best_pred))\n",
    "RMSE_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies_array = np.repeat(y_test_best_pred,23, axis=-1)\n",
    "original_copies_array = np.repeat(testY,23, axis=-1)\n",
    "\n",
    "pred = scaler.inverse_transform(np.reshape(prediction_copies_array,(len(y_test_best_pred),23)))[:,0]\n",
    "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),23)))[:,0]\n",
    "\n",
    "# Flattening the predictions and actual values\n",
    "y_test_flat = np.ravel(original)\n",
    "y_pred_flat = np.ravel(pred)\n",
    "\n",
    "# Plotting\n",
    "indices = np.arange(len(y_test_flat))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(indices, y_test_flat, label='Actual Daily VOL', color='teal')\n",
    "plt.plot(indices, y_pred_flat, label='Predicted Daily VOL', color='red', linestyle='--')\n",
    "\n",
    "plt.title('Actual vs. Predicted Daily VOL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# MAPE\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "#NMSE\n",
    "def nmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    variance = np.var(y_true)\n",
    "    return mse / variance\n",
    "\n",
    "#DA\n",
    "def DA(y_true, y_pred):\n",
    "    # Convert the arrays to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Calculate the direction of change\n",
    "    true_direction = np.sign(np.diff(y_true))\n",
    "    pred_direction = np.sign(np.diff(y_pred))\n",
    "    \n",
    "    # Compare directions\n",
    "    correct_direction = np.sum(true_direction == pred_direction)\n",
    "    total_direction = len(true_direction)\n",
    "    \n",
    "    # Calculate directional accuracy\n",
    "    da = correct_direction / total_direction * 100\n",
    "    \n",
    "    return da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test_flat\n",
    "y_predi = y_pred_flat\n",
    "\n",
    "print(\"RMSE: \", rmse(y_true, y_predi))\n",
    "print(\"MAPE: \", mape(y_true, y_predi))\n",
    "print(\"NMSE: \", nmse(y_true, y_predi))\n",
    "print(\"DA: \", DA(y_true, y_predi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "random_ind = np.random.choice(trainX.shape[0], 1000, replace=False)\n",
    "\n",
    "data = trainX[random_ind[0:1000]]\n",
    "\n",
    "explainer = shap.GradientExplainer((model.layers[0].input,\n",
    "                               model.layers[-1].output),\n",
    "                               data)\n",
    "\n",
    "shap_values = explainer(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reshape shap_values to 2D\n",
    "shap_values_2d = shap_values.values.reshape(-1, 23)\n",
    "\n",
    "# Reshape test1 to 2D\n",
    "test1_2d = data.reshape(-1, 23)\n",
    "\n",
    "# Create the summary plot\n",
    "feature_names = df_for_training.columns\n",
    "plt.figure(figsize=(5, 5))\n",
    "shap.summary_plot(shap_values_2d, test1_2d, feature_names=feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shap_values = np.mean(np.abs(shap_values_2d), axis=0)\n",
    "sorted_indices = np.argsort(mean_shap_values)[::-1]\n",
    "sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "sorted_mean_shap_values = np.array(mean_shap_values)[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.barh(sorted_feature_names, sorted_mean_shap_values, color='blue')\n",
    "plt.xlabel('Mean Absolute SHAP Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Mean Absolute SHAP Value for Each Feature')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest values on top\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
