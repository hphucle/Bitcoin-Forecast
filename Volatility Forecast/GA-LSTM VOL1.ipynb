{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BTC_Trial_NB.csv')\n",
    "df.index = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "df = df.drop(['Date', 'Month', 'Year', 'Network Difficulty'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_for_training=df[:1848]\n",
    "df_for_testing=df[1848:]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
    "\n",
    "df_for_testing_scaled=scaler.transform(df_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training_scaled.shape, df_for_testing_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
    "            dataY.append(dataset[i,3])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=createXY(df_for_training_scaled,30)\n",
    "testX,testY=createXY(df_for_testing_scaled,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(units, dropout, lr, batch_size, epochs, dense):\n",
    "\n",
    " #LSTM Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(abs(units), input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(LSTM(abs(units)))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(Dense(abs(dense), activation='tanh'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  optimizer = Adam(learning_rate=abs(lr)/10000.0, amsgrad=False)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(trainX, trainY, validation_split=0.2, epochs=abs(epochs), batch_size=abs(batch_size))\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "\n",
    "def evaluate(individual):\n",
    "  units, dropout, lr, batch_size, epochs, dense = individual\n",
    "\n",
    "  units = int(individual[0])\n",
    "  dropout = int(individual[1])\n",
    "  lr = int(individual[2])\n",
    "  batch_size = int(individual[3])\n",
    "  epochs = int(individual[4])\n",
    "  dense = int(individual[5])\n",
    "\n",
    "  print('\\nNum of neurons: ', units, '\\nEpochs:', epochs,'\\nBatch size:',batch_size,\n",
    "        '\\nLearning rate:', abs(lr)/10000.0,'\\nDropout rate:', abs(dropout)/100.0, '\\nDense:', dense)\n",
    "\n",
    "  #LSTM Model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(abs(units), input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(LSTM(abs(units)))\n",
    "  model.add(Dropout(abs(dropout)/100.0))\n",
    "  model.add(Dense(abs(dense), activation='tanh'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  optimizer = Adam(learning_rate=abs(lr)/10000.0, amsgrad=False)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "  # Train the model\n",
    "  model.fit(trainX, trainY, validation_split=0.2, epochs=abs(epochs), batch_size=abs(batch_size))\n",
    "\n",
    "  # Evaluate the model\n",
    "  loss, accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "  return loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(17) \n",
    "\n",
    "# Setup DEAP\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Possible parameter values\n",
    "units = range(16,129)\n",
    "dropout = range(0,41)\n",
    "lr = range(0,101)\n",
    "batch_size = range(32,129)\n",
    "epochs = range(20,51)\n",
    "dense = range(8,65) \n",
    "\n",
    "#Define variables\n",
    "toolbox.register(\"attr_units\", random.choice, units)  # Number of LSTM units\n",
    "toolbox.register(\"attr_dropout\", random.choice, dropout)  # Dropout rate\n",
    "toolbox.register(\"attr_lr\", random.choice, lr)  # Learning rate\n",
    "toolbox.register(\"attr_batch_size\", random.choice, batch_size)  # Batch size\n",
    "toolbox.register(\"attr_epochs\", random.choice, epochs)  # Number of epochs\n",
    "toolbox.register(\"attr_denses\", random.choice, dense)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_units, toolbox.attr_dropout, toolbox.attr_lr,\n",
    "                  toolbox.attr_batch_size, toolbox.attr_epochs, toolbox.attr_denses), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(\"Start time:\", start_time)\n",
    "hof = tools.HallOfFame(1)\n",
    "population = toolbox.population(n=20)\n",
    "algorithms.eaSimple(population, toolbox, cxpb = 0.7, mutpb = 0.2, ngen=20,\n",
    "                    halloffame=hof, verbose=True)\n",
    "best_individual = hof[0]\n",
    "end_time = datetime.now()\n",
    "print('End time:',end_time)\n",
    "time_elapsed = end_time-start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_units = int(best_individual[0])         # Number of LSTM units\n",
    "param_dropout = int(best_individual[1])       # Dropout rate\n",
    "param_lr = int(best_individual[2])            # Learning rate\n",
    "param_batch_size = int(best_individual[3])    # Batch size\n",
    "param_epochs = int(best_individual[4])        # Number of epochs\n",
    "param_denses = int(best_individual[5])        # Number of dense units\n",
    "\n",
    "print(param_units, param_dropout/100,param_lr/10000,param_batch_size, param_epochs, param_denses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(units=param_units,dropout=param_dropout, lr=param_lr,\n",
    "            batch_size=param_batch_size, epochs=param_epochs,dense=param_denses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_best_pred = model.predict(testX).flatten()\n",
    "best_test_result = pd.DataFrame(data= {'Test Pred':y_test_best_pred, 'Actual':testY.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE_tuned = np.sqrt(mean_squared_error(testY, y_test_best_pred))\n",
    "RMSE_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(best_test_result['Test Pred'], label='Predicted', color='red')\n",
    "plt.plot(best_test_result['Actual'], label='Actual', color='blue')\n",
    "plt.title('Close Price Values after tuning vs Actual Close Price')\n",
    "plt.legend(loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
